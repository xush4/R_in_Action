legend("topright", legend=2011:2009, fill=rainbow(3)[3:1])
Male_3y=rbind(Male2010,Male2011,Male2012)
colnames(Male_3y)<-c("illegal","illegal partly","Not illegal","Unsure")
rownames(Male_3y)<-c("2010","2011","2012")
Female_3y=rbind(Female2010,Female2011,Female2012)
colnames(Female_3y)<-c("illegal","illegal partly","Not illegal","Unsure")
rownames(Female_3y)<-c("2010","2011","2012")
par(mfrow=c(1,2))
barplot(Male_3y,main="Male Public Opinion on Legalizing Prostitution", xlab="Opinion",
ylab="Percentage", ylim=c(0,1), col=rainbow(3), beside=1)
legend("topright", legend=2011:2009, fill=rainbow(3)[3:1])
barplot(Female_3y,main="Female Public Opinion on Legalizing Prostitution", xlab="Opinion",
ylab="Percentage", ylim=c(0,1), col=rainbow(3), beside=1)
legend("topright", legend=2011:2009, fill=rainbow(3)[3:1])
Overall_3y=rbind(Overall2010,Overall2011,Overall2012)
colnames(Overall_3y)<-c("illegal","illegal in some acts","Not illegal","Unsure")
rownames(Overall_3y)<-c("2010","2011","2012")
par(mfrow=c(1,2))
barplot(Male_3y,main="Male Public Opinion on Legalizing Prostitution", xlab="(a) Male's Opinion",
ylab="Percentage", ylim=c(0,1), col=rainbow(3), beside=1)
legend("topright", legend=2011:2009, fill=rainbow(3)[3:1])
par(mfrow=c(1,2))
barplot(Male_3y,main="Male Public Opinion on Legalizing Prostitution", xlab="(a) Male's Opinion",
ylab="Percentage", ylim=c(0,1), col=rainbow(3), beside=1)
legend("topright", legend=2011:2009, fill=rainbow(3)[3:1])
barplot(Female_3y,main="Female Public Opinion on Legalizing Prostitution", xlab="(b) Female's Opinion",
ylab="Percentage", ylim=c(0,1), col=rainbow(3), beside=1)
legend("topright", legend=2011:2009, fill=rainbow(3)[3:1])
for (i in 0:19) {}
for (i in 0:19) {
sum=sum+0.5/(1.1^i)}
sum=0
for (i in 0:19) {
sum=sum+0.5/(1.1^i)}
sum
1/1.069^2
1.069^2/1.063
400/1.02^3
10000/0.06-10000/0.08
400*1.02^3
10000/0.08-10000/0.1
save.image("~/.RData")
1/(1.081^4)
105+100/1.05
100-100/1.04
100-100/1.05
100/1.05
2/(105-100/1.05)
0.204878*95.2381/1.02
20.45-19.13
(1.088^6-1)/6
3/(105-100/1.05)
95.23*0.3073/1.02
30.73-28.69
95.23*0.3073171/1.02
setwd("E:/Dropbox/Data Science/R_in_Action")
vars <- c("mpg", "hp", "wt")
head(mtcars[vars])
# Listing 7.1 - descriptive stats via summary
summary(mtcars[vars])
# Listing 7.2 - descriptive stats via sapply()
#
mystats <- function(x, na.omit = FALSE) {
if (na.omit)
x <- x[!is.na(x)]
m <- mean(x)
n <- length(x)
s <- sd(x)
skew <- sum((x - m)^3/s^3)/n
kurt <- sum((x - m)^4/s^4)/n - 3
return(c(n = n, mean = m, stdev = s, skew = skew, kurtosis = kurt))
}
sapply(mtcars[vars], mystats)
# save original graphic settings
opar <- par(no.readonly = TRUE)
vars <- c("mpg", "hp", "wt")
head(mtcars[vars])
# Listing 7.1 - descriptive stats via summary
summary(mtcars[vars])
# Listing 7.2 - descriptive stats via sapply()
#
mystats <- function(x, na.omit = FALSE) {
if (na.omit)
x <- x[!is.na(x)]
m <- mean(x)
n <- length(x)
s <- sd(x)
skew <- sum((x - m)^3/s^3)/n
kurt <- sum((x - m)^4/s^4)/n - 3
return(c(n = n, mean = m, stdev = s, skew = skew, kurtosis = kurt))
}
sapply(mtcars[vars], mystats)
#sapply 可以插入的经典函数有：mean、sd、var、min、max、median、length、range
#和quantile。其他函数需要自己写出：例如上方的mystats。
#对于mystats结果的解释：对于样本中的32种车型，每加仑汽油行驶英里数的平均值为20.1，标准差为6.0。分布呈现右偏（偏
#度+0.61），并且较正态分布稍平（峰度???0.37）。
# Listing 7.3 - Descriptive statistics (Hmisc package)
library(Hmisc)
describe(mtcars[vars])
# Listing 7.4 - Descriptive statistics (pastecs package)
library(pastecs)
stat.desc(mtcars[vars])
# Listing 7.5 - Descriptive statistics (psych package)
library(psych)
describe(mtcars[vars])
library(Hmisc)
describe(mtcars[vars])
library(pastecs)
stat.desc(mtcars[vars])
library(psych)
describe(mtcars[vars])
install.packages("psych")
install.packages("pastecs")
library(pastecs)
stat.desc(mtcars[vars])
a=stat.desc(mtcars[vars])
a[12,'']
a[12,]
a["SE.mean",]
# Listing 7.6 - Descriptive statistics by group with aggregate()
aggregate(mtcars[vars], by = list(am = mtcars$am), mean)
aggregate(mtcars[vars], by = list(am = mtcars$am), sd)
# Listing 7.7 - Descriptive statistics by group via by()
dstats <- function(x)(c(mean=mean(x), sd=sd(x)))
by(mtcars[vars], mtcars$am, dstats)
aggregate(mtcars[vars], by = list(am = mtcars$am), mean)
aggregate(mtcars[vars], by = list(am = mtcars$am), sd)
# Listing 7.7 - Descriptive statistics by group via by()
dstats <- function(x)(c(mean=mean(x), sd=sd(x)))
by(mtcars[vars], mtcars$am, dstats)
aggregate(mtcars[vars], by = list(am = mtcars$am), mean)
mtcars
vars <- c("mpg", "hp", "wt")
aggregate(mtcars[vars], by = list(am = mtcars$am), mean)
aggregate(mtcars[vars], by = list(am = mtcars$am), sd)
# Listing 7.7 - Descriptive statistics by group via by()
dstats <- function(x)(c(mean=mean(x), sd=sd(x)))
by(mtcars[vars], mtcars$am, dstats)
dstats <- function(x)(c(mean=mean(as.numeric(x), sd=sd(as.numeric(x)))
)
)
dstats <- function(x)(c(mean=mean(as.numeric(x)), sd=sd(as.numeric(x)))
）
dstats <- function(x)(c(mean=mean(as.numeric(x)), sd=sd(as.numeric(x))))
by(mtcars[vars], mtcars$am, dstats)
mtcars[vars]
a=mtcars[vars]
is.numeric(a)
as.numweic(a)
as.numeric(a)
as.matrix(a)
dstats <- function(x)(c(mean=mean(as.matrix(x)), sd=sd(as.matrix(x))))
by(mtcars[vars], mtcars$am, dstats)
mytable <- xtabs(~ Treatment+Improved, data=Arthritis)
mytable
Arthritis
Arthritis
library(vcd)
mytable <- with(Arthritis, table(Improved))
mytable <- xtabs(~ Treatment+Improved, data=Arthritis)
mytable
margin.table(mytable, 1)
margin.table(mytable, 2)
prop.table(mytable)
prop.table(mytable)#各项统计（比率）
addmargins(mytable)
admargins(prop.table(mytable))
addmargins(prop.table(mytable))
addmargins(prop.table(mytable, 1), 2)
addmargins(prop.table(mytable, 2, 1)
library(gmodels)
install.packages("gmodels")
library(gmodels)
CrossTable(Arthritis$Treatment, Arthritis$Improved)
library(vcd)
mytable <- xtabs(~Treatment+Improved, data=Arthritis)
chisq.test(mytable)
mytable <- xtabs(~Improved+Sex, data=Arthritis)
chisq.test(mytable)
mytable <- xtabs(~Treatment+Improved, data=Arthritis)
fisher.test(mytable)
mytable <- xtabs(~Treatment+Improved+Sex, data=Arthritis)
mantelhaen.test(mytable)
assocstats(mytable)
mytable <- xtabs(~Treatment+Improved, data=Arthritis)
assocstats(mytable)
table2flat <- function(mytable) {
df <- as.data.frame(mytable)
rows <- dim(df)[1]
cols <- dim(df)[2]
x <- NULL
for (i in 1:rows) {
for (j in 1:df$Freq[i]) {
row <- df[i, c(1:(cols - 1))]
x <- rbind(x, row)
}
}
row.names(x) <- c(1:dim(x)[1])
return(x)
}
# Listing 7.16 - Using table2flat with published data
treatment <- rep(c("Placebo", "Treated"), 3)
improved <- rep(c("None", "Some", "Marked"), each = 2)
Freq <- c(29, 13, 7, 7, 7, 21)
mytable <- as.data.frame(cbind(treatment, improved, Freq))
mydata <- table2flat(mytable)
head(mydata)
states <- state.x77[, 1:6]
cov(states)#方差与协方差
cor(states)#Pearson
cor(states, method="spearman")#Spearman，此处也可以设置为kendall
#首个语句计算了方差和协方差，第二个语句则计算了Pearson积差相关系数，而第三个语句计算
#了Spearman等级相关系数。举例来说，我们可以看到收入和高中毕业率之间存在很强的正相关，
#而文盲率和预期寿命之间存在很强的负相关。
x <- states[, c("Population", "Income", "Illiteracy", "HS Grad")]
y <- states[, c("Life Exp", "Murder")]
cor(x, y)
library(psych)
corr.test(states, use = "complete")
short=F
corr.test(states, use = "complete")
#independent t-test
library(MASS)
t.test(Prob ~ So, data=UScrime)
# dependent t-test
library(MASS)
sapply(UScrime[c("U1", "U2")], function(x) (c(mean = mean(x),
sd = sd(x))))
with(UScrime, t.test(U1, U2, paired = TRUE))
#independent t-test
library(MASS)
t.test(Prob ~ So, data=UScrime)
class <- state.region
var <- state.x77[, c("Illiteracy")]
mydata <- as.data.frame(cbind(class, var))
rm(class,var)
library(npmc)
summary(npmc(mydata), type = "BF")
install.packages("npmc")
install.packages("D:/谷歌下载/npmc_1.0-7.zip", repos = NULL)
library(npmc)
install.packages("mvtnorm")
library(npmc)
summary(npmc(mydata), type = "BF")
aggregate(mydata, by = list(mydata$class), median)
mydata
library(multcomp)
install.packages("multcomp")
attach(cholesterol)
library(multcomp)
attach(cholesterol)
table(trt)
aggregate(response, by=list(trt), FUN=mean)
aggregate(response, by=list(trt), FUN=sd)
fit <- aov(response ~ trt)
summary(fit)
library(gplots)
install.packages("gplots")
library(gplots)
plotmeans(response ~ trt, xlab="Treatment", ylab="Response",
main="Mean Plot\nwith 95% CI")
detach(cholesterol)
opar <- par(no.readonly = TRUE)
# Listing 9.2 - Tukey HSD pairwise group comparisons
TukeyHSD(fit)
par(las=2)
par(mar=c(5,8,4,2))
plot(TukeyHSD(fit))
par(opar)
# Multiple comparisons the multcomp package
library(multcomp)
tuk <- glht(fit, linfct=mcp(trt="Tukey"))
#glht()函数提供了多重均值比较更为全面的方法，既适用于线性模型（如本章各例），也适用
#于广义线性模型（见第13章）。下面的代码重现了Tukey HSD检验，并用一个不同的图形对结果
#进行展示:
plot(cld(tuk, level=.05),col="lightgrey")
plot(cld(tuk, level=.05),col="lightgrey",cex=0.5)
plot(cld(tuk, level=.05),col="lightgrey")
plot(cld(tuk, level=.05),col="lightgrey",cex=0.2)
plot(cld(tuk, level=.05),col="lightgrey",cex=0.2)
library(multcomp)
par(mar=c(5,4,6,2),oma=c(2,2,2,2))
tuk <- glht(fit, linfct=mcp(trt="Tukey"))
#glht()函数提供了多重均值比较更为全面的方法，既适用于线性模型（如本章各例），也适用
#于广义线性模型（见第13章）。下面的代码重现了Tukey HSD检验，并用一个不同的图形对结果
#进行展示:
plot(cld(tuk, level=.05),col="lightgrey")
par(mar=c(5,4,6,2),oma=c(1,1,1,1))
tuk <- glht(fit, linfct=mcp(trt="Tukey"))
#glht()函数提供了多重均值比较更为全面的方法，既适用于线性模型（如本章各例），也适用
#于广义线性模型（见第13章）。下面的代码重现了Tukey HSD检验，并用一个不同的图形对结果
#进行展示:
plot(cld(tuk, level=.05),col="lightgrey")
par(opar)
par(opar)
par(oma=c(1,1,1,1))
#oma:增加边框外
tuk <- glht(fit, linfct=mcp(trt="Tukey"))
#glht()函数提供了多重均值比较更为全面的方法，既适用于线性模型（如本章各例），也适用
#于广义线性模型（见第13章）。下面的代码重现了Tukey HSD检验，并用一个不同的图形对结果
#进行展示:
plot(cld(tuk, level=.05),col="lightgrey")
library(multcomp)
par(oma=c(2,2,2,2))
#oma:增加边框外
tuk <- glht(fit, linfct=mcp(trt="Tukey"))
#glht()函数提供了多重均值比较更为全面的方法，既适用于线性模型（如本章各例），也适用
#于广义线性模型（见第13章）。下面的代码重现了Tukey HSD检验，并用一个不同的图形对结果
#进行展示:
plot(cld(tuk, level=.05),col="lightgrey")
par(opar)
library(car)
qqPlot(lm(response ~ trt, data=cholesterol),
simulate=TRUE, main="Q-Q Plot", labels=FALSE)
# Assessing homogeneity of variances
bartlett.test(response ~ trt, data=cholesterol)
library(car)
outlierTest(fit)
attach(ToothGrowth)
table(supp,dose)
aggregate(len, by=list(supp,dose), FUN=mean)
aggregate(len, by=list(supp,dose), FUN=sd)
dose <- factor(dose)
fit <- aov(len ~ supp*dose)
summary(fit)
# plotting interactions
interaction.plot(dose, supp, len, type="b",
col=c("red","blue"), pch=c(16, 18),
main = "Interaction between Dose and Supplement Type")
library(gplots)
plotmeans(len ~ interaction(supp, dose, sep=" "),
connect=list(c(1, 3, 5),c(2, 4, 6)),
col=c("red","darkgreen"),
main = "Interaction Plot with 95% CIs",
xlab="Treatment and Dose Combination")
library(HH)
interaction2wt(len~supp*dose)
install.packages("HH")
library(HH)
interaction2wt(len~supp*dose)
summary(fit)
CO2$conc <- factor(CO2$conc)
w1b1 <- subset(CO2, Treatment=='chilled')
fit <- aov(uptake ~ (conc*Type) + Error(Plant/(conc)), w1b1)
summary(fit)
par(las=2)
par(mar=c(10,4,4,2))
with(w1b1,
interaction.plot(conc,Type,uptake,
type="b", col=c("red","blue"), pch=c(16,18),
main="Interaction Plot for Plant Type and Concentration"))
boxplot(uptake ~ Type*conc, data=w1b1, col=(c("gold","green")),
main="Chilled Quebec and Mississippi Plants",
ylab="Carbon dioxide uptake rate (umol/m^2 sec)")
par(opar)
CO2$conc <- factor(CO2$conc)
w1b1 <- subset(CO2, Treatment=='chilled')
fit <- aov(uptake ~ (conc*Type) + Error(Plant/(conc)), w1b1)
summary(fit)
par(las=2)
par(mar=c(10,4,4,2))
with(w1b1,
interaction.plot(conc,Type,uptake,
type="b", col=c("red","blue"), pch=c(16,18),
main="Interaction Plot for Plant Type and Concentration"))
boxplot(uptake ~ Type*conc, data=w1b1, col=(c("gold","green")),
main="Chilled Quebec and Mississippi Plants",
ylab="Carbon dioxide uptake rate (umol/m^2 sec)")
CO2$conc <- factor(CO2$conc)
w1b1 <- subset(CO2, Treatment=='chilled')
fit <- aov(uptake ~ (conc*Type) + Error(Plant/(conc)), w1b1)
summary(fit)
library(MASS)
attach(UScereal)
shelf <- factor(shelf)
y <- cbind(calories, fat, sugars)
aggregate(y, by=list(shelf), FUN=mean)
cov(y)
fit <- manova(y ~ shelf)
summary(fit)
summary.aov(fit)
center <- colMeans(y)
n <- nrow(y)
p <- ncol(y)
cov <- cov(y)
d <- mahalanobis(y,center,cov)
coord <- qqplot(qchisq(ppoints(n),df=p),
d, main="QQ Plot Assessing Multivariate Normality",
ylab="Mahalanobis D2")
abline(a=0,b=1)
identify(coord$x, coord$y, labels=row.names(UScereal))
# multivariate outliers
library(mvoutlier)
install.packages("mvoutlier")
library(mvoutlier)
outliers <- aq.plot(y)
outliers
library(rrcov)
Wilks.test(y,shelf, method="mcd")  # this can take a while
# Listing 9.11 - A regression approach to the Anova problem
fit.lm <- lm(response ~ trt, data=cholesterol)
summary(fit.lm)
opar <- par(no.readonly = TRUE)
par(ask=TRUE)
library(pwr)
# t tests
pwr.t.test(d=.8, sig.level=.05,power=.9, type="two.sample",
alternative="two.sided")
install.packages("pwr")
library(pwr)
# t tests
pwr.t.test(d=.8, sig.level=.05,power=.9, type="two.sample",
alternative="two.sided")
pwr.t.test(n=20, d=.5, sig.level=.01, type="two.sample",
alternative="two.sided")
pwr.anova.test(k=5,f=.25,sig.level=.05,power=.8)
pwr.r.test(r=.25, sig.level=.05, power=.90, alternative="greater")
pwr.r.test(r=.25, sig.level=.05, power=.90, alternative="greater")
prob <- matrix(c(.42, .28, .03, .07, .10, .10), byrow=TRUE, nrow=3)
ES.w2(prob)
pwr.chisq.test(w=.1853, df=3 , sig.level=.05, power=.9)
pwr.chisq.test(w=.1853, df=2 , sig.level=.05, power=.9)
help("pwr.chisq.test")
# 检验各种效应值下的相关性所需的样本量曲线
es <- seq(.1, .5, .01)
nes <- length(es)
samsize <- NULL
for (i in 1:nes){
result <- pwr.anova.test(k=5, f=es[i], sig.level=.05, power=.9)
samsize[i] <- ceiling(result$n)
}
plot(samsize,es, type="l", lwd=2, col="red",
ylab="Effect Size",
xlab="Sample Size (per cell)",
main="One Way ANOVA with Power=.90 and Alpha=.05")
opar <- par(no.readonly = TRUE)
par(ask=TRUE)
par(opar)
es <- seq(.1, .5, .01)
nes <- length(es)
samsize <- NULL
for (i in 1:nes){
result <- pwr.anova.test(k=5, f=es[i], sig.level=.05, power=.9)
samsize[i] <- ceiling(result$n)
}
plot(samsize,es, type="l", lwd=2, col="red",
ylab="Effect Size",
xlab="Sample Size (per cell)",
main="One Way ANOVA with Power=.90 and Alpha=.05")
par(ask=F)
opar <- par(no.readonly = TRUE)
# 检验各种效应值下的相关性所需的样本量曲线
es <- seq(.1, .5, .01)
nes <- length(es)
samsize <- NULL
for (i in 1:nes){
result <- pwr.anova.test(k=5, f=es[i], sig.level=.05, power=.9)
samsize[i] <- ceiling(result$n)
}
plot(samsize,es, type="l", lwd=2, col="red",
ylab="Effect Size",
xlab="Sample Size (per cell)",
main="One Way ANOVA with Power=.90 and Alpha=.05")
par(c(1,1))
par(mfrow=c(1,1))
opar <- par(no.readonly = TRUE)
# 检验各种效应值下的相关性所需的样本量曲线
es <- seq(.1, .5, .01)
nes <- length(es)
samsize <- NULL
for (i in 1:nes){
result <- pwr.anova.test(k=5, f=es[i], sig.level=.05, power=.9)
samsize[i] <- ceiling(result$n)
}
plot(samsize,es, type="l", lwd=2, col="red",
ylab="Effect Size",
xlab="Sample Size (per cell)",
main="One Way ANOVA with Power=.90 and Alpha=.05")
library(pwr)
r <- seq(.1,.5,.01)
nr <- length(r)
p <- seq(.4,.9,.1)
np <- length(p)
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
for (j in 1:nr){
result <- pwr.r.test(n = NULL, r = r[j],
sig.level = .05, power = p[i],
alternative = "two.sided")
samsize[j,i] <- ceiling(result$n)
}
}
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
xlab="Correlation Coefficient (r)",
ylab="Sample Size (n)" )
for (i in 1:np){
lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2, col="gray89")
title("Sample Size Estimation for Correlation Studies\n
Sig=0.05 (Two-tailed)")
legend("topright", title="Power", as.character(p),
fill=colors)
talk
load("D:/谷歌下载/talk.RData")
talk
hist(talk$WordsPerDay~talk$GenderMale1)
hist(talk$WordsPerDay)
